# Default values for anime-reminder.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.


fullnameOverride: ""
nameOverride: ""

ui:
  replicaCount: 2

  image:
    repository: nightmare224/anime-reminder-ui
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: "latest"

  imagePullSecrets: []
  
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  service:
    type: ClusterIP
    port: 80

  resources: {}

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 50%
      maxSurge: 100%

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  tolerations: []

  affinity: {}

  healthCheck:
    enabled: false


  devMode:
    enabled: false
    codePathOfLocal: /home/thl/Documents/softwareContainerization/final-project/app-service/anime-reminder/app/ui/src
    codePathOfPod: /opt/src

  canary:
    enabled: false
    replicaCount: 1
    image:
      repository: nightmare224/anime-reminder-ui
      tag: "1.0.1"


api:
  replicaCount: 2

  image:
    repository: nightmare224/anime-reminder-api
    pullPolicy: Always
    # Overrides the image tag whose default is the chart appVersion.
    tag: "latest"

  imagePullSecrets: []
  
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  service:
    type: ClusterIP
    port: 80
    # default is None
    sessionAffinity: ClientIP

  resources: {}

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 50%
      maxSurge: 100%

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  tolerations: []

  affinity: {}

  healthCheck:
    enabled: false

  podAnnotations: {}

  podSecurityContext: {}

  securityContext: {}

  extraEnvFrom: |
    - secretRef: 
        name: anime-reminder-common

  devMode:
    enabled: false
    codePathOfLocal: /home/thl/Documents/softwareContainerization/final-project/app-service/anime-reminder/app/api/src
    codePathOfPod: /opt/src

  canary:
    enabled: false
    replicaCount: 1
    image:
      repository: nightmare224/anime-reminder-api
      tag: "latest"

keycloak:
  replicaCount: 1

  image:
    # The Keycloak image repository
    repository: quay.io/keycloak/keycloak
    # Overrides the Keycloak image tag whose default is the chart appVersion
    tag: "17.0.1-legacy"
    # The Keycloak image pull policy
    pullPolicy: IfNotPresent

  # Image pull secrets for the Pod
  imagePullSecrets: []

  command: []
  args: []

  admin:
    username: ""
    password: ""

  serviceAccount:
    # Specifies whether a ServiceAccount should be created
    create: true
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""
    # Additional annotations for the ServiceAccount
    annotations: {}
    # Additional labels for the ServiceAccount
    labels: {}
    # Image pull secrets that are attached to the ServiceAccount
    imagePullSecrets: []

  hostAliases: []

  extraEnv: |
    - name: DB_VENDOR
      value: postgres
    - name: DB_ADDR
      value: ar-postgresql.anime-reminder.svc.cluster.local
    - name: DB_PORT
      value: "5432"
    - name: DB_DATABASE
      value: keycloak
    - name: PROXY_ADDRESS_FORWARDING
      value: "true"
    - name: KEYCLOAK_IMPORT
      value: /realm/realm-import.json

  extraEnvFrom: |
    - secretRef: 
        name: anime-reminder-common
  extraPorts: []

  livenessProbe: |
    httpGet:
      path: /auth/
      port: http
    initialDelaySeconds: 0
    timeoutSeconds: 5

  # Readiness probe configuration
  readinessProbe: |
    httpGet:
      path: /auth/realms/master
      port: http
    initialDelaySeconds: 30
    timeoutSeconds: 1

  startupProbe: |
    httpGet:
      path: /auth/
      port: http
    initialDelaySeconds: 30
    timeoutSeconds: 1
    failureThreshold: 60
    periodSeconds: 5

  resources: {}

  extraContainers: ""

  extraConfigMap:
    name: realm-import

  # Add additional volumes, e. g. for custom themes
  extraVolumes: |
    - name: realm-import
      configMap:
        name: realm-import

  # Add additional volumes mounts, e. g. for custom themes
  extraVolumeMounts: |
    - name: realm-import
      mountPath: "/realm/"
      readOnly: true

  startupScripts:
    # WildFly CLI script for configuring the node-identifier
    keycloak.cli: |
      {{- .Files.Get "files/keycloak/keycloak.cli" }}

  enableServiceLinks: true
  restartPolicy: Always

  lifecycleHooks: |

  statefulsetAnnotations: {}
  statefulsetLabels: {}

  autoscaling:
    # If `true`, a autoscaling/v2beta2 HorizontalPodAutoscaler resource is created (requires Kubernetes 1.18 or above)
    # Autoscaling seems to be most reliable when using KUBE_PING service discovery (see README for details)
    # This disables the `replicas` field in the StatefulSet
    enabled: false
    # Additional HorizontalPodAutoscaler labels
    labels: {}
    # The minimum and maximum number of replicas for the Keycloak StatefulSet
    minReplicas: 3
    maxReplicas: 10
    # The metrics to use for scaling
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 80
    # The scaling policy to use. This will scale up quickly but only scale down a single Pod per 5 minutes.
    # This is important because caches are usually only replicated to 2 Pods and if one of those Pods is terminated this will give the cluster time to recover.
    behavior:
      scaleDown:
        stabilizationWindowSeconds: 300
        policies:
          - type: Pods
            value: 1
            periodSeconds: 300

  podDisruptionBudget: {}

  podManagementPolicy: Parallel

  # StatefulSet's update strategy
  updateStrategy: RollingUpdate

  secrets: {}

  podAnnotations: {}
  podLabels: {}

  podSecurityContext:
    fsGroup: 1000

  # SecurityContext for the Keycloak container
  securityContext:
    runAsUser: 1000
    runAsNonRoot: true

  skipInitContainers: false
  extraInitContainers: ""

  priorityClassName: ""

  terminationGracePeriodSeconds: 60

  topologySpreadConstraints:
  tolerations: []
  nodeSelector: {}
  
  affinity: |
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              component: keycloak
            matchExpressions:
              - key: app.kubernetes.io/component
                operator: NotIn
                values:
                  - test
          topologyKey: kubernetes.io/hostname
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                component: keycloak
              matchExpressions:
                - key: app.kubernetes.io/component
                  operator: NotIn
                  values:
                    - test
            topologyKey: failure-domain.beta.kubernetes.io/zone

  service:
    # Annotations for headless and HTTP Services
    annotations: {}
    # Additional labels for headless and HTTP Services
    labels: {}
    # key: value
    # The Service type
    type: ClusterIP
    # Optional IP for the load balancer. Used for services of type LoadBalancer only
    loadBalancerIP: ""
    # The http Service port
    httpPort: 80
    # The HTTP Service node port if type is NodePort
    httpNodePort: null
    # The HTTPS Service port
    httpsPort: 8443
    # The HTTPS Service node port if type is NodePort
    httpsNodePort: null
    # The WildFly management Service port
    httpManagementPort: 9990
    # The WildFly management Service node port if type is NodePort
    httpManagementNodePort: null
    # Additional Service ports, e. g. for custom admin console
    extraPorts: []
    # When using Service type LoadBalancer, you can restrict source ranges allowed
    # to connect to the LoadBalancer, e. g. will result in Security Groups
    # (or equivalent) with inbound source ranges allowed to connect
    loadBalancerSourceRanges: []
    # When using Service type LoadBalancer, you can preserve the source IP seen in the container
    # by changing the default (Cluster) to be Local.
    # See https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    externalTrafficPolicy: "Cluster"
    # Session affinity
    # See https://kubernetes.io/docs/concepts/services-networking/service/#proxy-mode-userspace
    sessionAffinity: ""
    # Session affinity config
    sessionAffinityConfig: {}

  networkPolicy:
    # If true, the Network policies are deployed
    enabled: false

    # Additional Network policy labels
    labels: {}

    # Define all other external allowed source
    # See https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#networkpolicypeer-v1-networking-k8s-io
    extraFrom: []

  prometheusRule:
    # If `true`, a PrometheusRule resource for the prometheus-operator is created
    enabled: false
    # Annotations for the PrometheusRule
    annotations: {}
    # Additional labels for the PrometheusRule
    labels: {}
    # List of rules for Prometheus
    rules: []

  rbac:
    create: false
    rules: []

  serviceMonitor:
    # If `true`, a ServiceMonitor resource for the prometheus-operator is created
    enabled: false
    # Optionally sets a target namespace in which to deploy the ServiceMonitor resource
    namespace: ""
    # Optionally sets a namespace for the ServiceMonitor
    namespaceSelector: {}
    # Annotations for the ServiceMonitor
    annotations: {}
    # Additional labels for the ServiceMonitor
    labels: {}
    # Interval at which Prometheus scrapes metrics
    interval: 10s
    # Timeout for scraping
    scrapeTimeout: 10s
    # The path at which metrics are served
    path: /metrics
    # The Service port at which metrics are served
    port: http-management

  extraServiceMonitor:
    # If `true`, a ServiceMonitor resource for the prometheus-operator is created
    enabled: false
    # Optionally sets a target namespace in which to deploy the ServiceMonitor resource
    namespace: ""
    # Optionally sets a namespace for the ServiceMonitor
    namespaceSelector: {}
    # Annotations for the ServiceMonitor
    annotations: {}
    # Additional labels for the ServiceMonitor
    labels: {}
    # Interval at which Prometheus scrapes metrics
    interval: 10s
    # Timeout for scraping
    scrapeTimeout: 10s
    # The path at which metrics are served
    path: /auth/realms/master/metrics
    # The Service port at which metrics are served
    port: http

  route:
    # If `true`, an OpenShift Route is created
    enabled: false
    # Path for the Route
    path: /
    # Route annotations
    annotations: {}
    # Additional Route labels
    labels: {}
    # Host name for the Route
    host: ""
    # TLS configuration
    tls:
      # If `true`, TLS is enabled for the Route
      enabled: true
      # Insecure edge termination policy of the Route. Can be `None`, `Redirect`, or `Allow`
      insecureEdgeTerminationPolicy: Redirect
      # TLS termination of the route. Can be `edge`, `passthrough`, or `reencrypt`
      termination: edge


postgresql:
  replicaCount: 2

  image:
    repository: postgres
    tag: "11.5"
    pullPolicy: IfNotPresent

  volumePermissions:
    enabled: true
    image:
      registry: docker.io
      repository: debian
      tag: buster-slim
      ## Specify a imagePullPolicy
      ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
      ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
      ##
      pullPolicy: Always
      ## Optionally specify an array of imagePullSecrets.
      ## Secrets must be manually created in the namespace.
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
      ##
      # pullSecrets:
      #   - myRegistryKeySecretName
    ## Init container Security Context
    securityContext:
      runAsUser: 0

  persistence:
    enabled: true
    storageClass: longhorn
    mountPath: /var/lib/postgresql
    subPath: ""
    accessModes:  [ReadWriteOnce]
    ## Storage Capacity for persistent volume
    size: 3Gi
    annotations: {}

  resources: {}

  nodeSelector: {}

  securityContext:
    enabled: true
    fsGroup: 1001
    runAsUser: 1001

  postgresql:
    username: ""
    password: ""
    database: postgres
    port: 5432
    # initdbArgs 
    # initdbWalDir
    dataDir: /var/lib/postgresql/data/pgdata

  extraEnvFrom: |
    - secretRef: 
        name: anime-reminder-common

  service:
    type: ClusterIP
    annotations: {}

  networkPolicy:
    # If true, the Network policies are deployed
    enabled: true

  ldap:
    enabled: false
    pgldapconfig: |-
      # Reference: https://github.com/larskanis/pg-ldap-sync/blob/master/config/sample-config.yaml
      # Connection parameters to LDAP server
      ldap_connection:
        host: example.com
        port: 389
        auth:
          method: :simple
          username: cn=admin,dc=example,dc=com
          password: -password-goes-here-

        # Search parameters for LDAP users which should be synchronized
      ldap_users:
        base: OU=People,dc=example,dc=com
        # LDAP filter (according to RFC 2254)
        # defines to users in LDAP to be synchronized
        filter: (&(objectClass=person)(objectClass=organizationalPerson)(givenName=*)(sn=*))
        # this attribute is used as PG role name
        name_attribute: sAMAccountName
        # lowercase name for use as PG role name
        lowercase_name: true
      ldap_groups:
          base: OU=people,dc=example,dc=com
          filter: (|(cn=group1)(cn=group2)(cn=group3))
          # this attribute is used as PG role name
          name_attribute: cn
          # this attribute must reference to all member DN's of the given group
          member_attribute: member
      # Connection parameters to PostgreSQL server
      # see also: http://rubydoc.info/gems/pg/PG/Connection#initialize-instance_method
      pg_connection:
        host: 
        dbname: postgres # the db name is usually "postgres"
        user: postgres # the user name is usually "postgres"
        password: postgres # kubectl get secret --namespace fadi <pod_name> -o jsonpath="{.data.postgresql-password}" | base64 --decode
      pg_users:
        # Filter for identifying LDAP generated users in the database.
        # It's the WHERE-condition to "SELECT rolname, oid FROM pg_roles"
        filter: rolcanlogin AND NOT rolsuper
        # Options for CREATE RULE statements
        create_options: LOGIN
      pg_groups:
        # Filter for identifying LDAP generated groups in the database.
        # It's the WHERE-condition to "SELECT rolname, oid FROM pg_roles"
        filter: NOT rolcanlogin AND NOT rolsuper
        # Options for CREATE RULE statements
        create_options: NOLOGIN
        grant_options:

    cron:
      schedule: "*/1 * * * *"
      repo: ceticasbl/pg-ldap-sync
      tag: latest
      restartPolicy: Never
      mountPath: /workspace
      subPath: ""

ingress:
  enabled: true
  className: ""
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/proxy-buffer-size: 128k
    nginx.ingress.kubernetes.io/affinity: cookie
    nginx.ingress.kubernetes.io/affinity-mode: persistent
    nginx.ingress.kubernetes.io/app-root: /animereminder/ui/home
    cert-manager.io/common-name: anime-reminder-cert
    cert-manager.io/issuer: anime-reminder-issuer
  hosts:
    - host: sc23.group40.io
      paths:
        - path: /animereminder/api
          pathType: Prefix
          serviceName: ar-api
          servicePort: 80
        - path: /animereminder/ui
          pathType: Prefix
          serviceName: ar-ui
          servicePort: 80
        - path: /auth
          pathType: Prefix
          serviceName: ar-keycloak-http
          servicePort: 80
  tls:
    - secretName: anime-reminder-tls-secret
      hosts:
        - sc23.group40.io


loadBalancer:
  ip: 192.168.0.112